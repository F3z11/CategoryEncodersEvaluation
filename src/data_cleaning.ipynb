{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dku6zN9YHBJq"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8gPqrWsMCwx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.impute import SimpleImputer\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPb_V9UwD7s"
      },
      "source": [
        "Compute minASPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuKWTBhowI57"
      },
      "outputs": [],
      "source": [
        "def column_types(df):\n",
        "    \"\"\"\n",
        "        Identifies numeric and categorical columns in a DataFrame.\n",
        "\n",
        "        Parameters:\n",
        "        df (pd.DataFrame): The input DataFrame for which column types are to be identified.\n",
        "\n",
        "        Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - num_cols (list): List of column names identified as numeric.\n",
        "            - cat_cols (list): List of column names identified as categorical.\n",
        "    \"\"\"\n",
        "\n",
        "    cols = df.columns\n",
        "    num_cols = df._get_numeric_data().columns.tolist()\n",
        "    cat_cols = list(set(cols) - set(num_cols))\n",
        "    \n",
        "    return num_cols, cat_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-NPSJFkwDsW"
      },
      "outputs": [],
      "source": [
        "def min_aspl(data):\n",
        "  \"\"\"\n",
        "    Computes the minASPL value based on the categorical columns in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The input DataFrame to calculate the minASPL.\n",
        "\n",
        "    Returns:\n",
        "        float: The minASPL rounded to the nearest integer.\n",
        "  \"\"\"\n",
        "  cat_cols = column_types(data)[1]\n",
        "  max_card = max(data[cat_cols].apply(lambda x: x.nunique()))\n",
        "  dim = len(data)\n",
        "  aspl = round(dim/max_card, 0)\n",
        "\n",
        "  return aspl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8pnbMJ6GC7B"
      },
      "source": [
        "Datasets importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtiPgNGvxpZN"
      },
      "outputs": [],
      "source": [
        "#Classification datasets\n",
        "\n",
        "datasets = []\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/census.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/mushrooms.csv', na_values='?'))\n",
        "\n",
        "churn = pd.read_csv('/data_raw/class/churn.csv', na_values='?')\n",
        "\n",
        "cols = ['\\'number_customer_service_calls\\'', '\\'state\\'', '\\'international_plan\\'', '\\'voice_mail_plan\\'', '\\'number_customer_service_calls\\'']\n",
        "for col in cols:\n",
        "    churn[col] = churn[col].astype('str')\n",
        "\n",
        "datasets.append(churn)\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/germancredit.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/breastcancer.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/autism_adult.csv', na_values='?'))\n",
        "\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/obesity.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/car.csv', na_values='?'))\n",
        "\n",
        "cmc = pd.read_csv('/data_raw/class/cmc.csv', na_values='?')\n",
        "cols = ['wife_edu', 'husband_edu', 'wife_religion',\n",
        "       'wife_working', 'husband_occupation', 'standard_of_living_index',\n",
        "       'media_exposure', 'target']\n",
        "for col in cols:\n",
        "    cmc[col] = cmc[col].astype('str')\n",
        "\n",
        "datasets.append(cmc)\n",
        "\n",
        "datasets.append(pd.read_csv('/data_raw/class/nursery.csv', na_values='?'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZhTk0Oh3Ff0"
      },
      "outputs": [],
      "source": [
        "#Regression datasets\n",
        "\n",
        "filepaths = glob.glob('/data_raw/regr/*.csv')\n",
        "\n",
        "all_dfs = [pd.read_csv(fp, na_values='?') for fp in filepaths]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLg7FhQ7GMfy"
      },
      "source": [
        "#### Compute the minASPL value for each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgCQ_eXe3gCe",
        "outputId": "e3d0004b-03c5-4ab4-8e5d-83748104f2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1191.0\n",
            "677.0\n",
            "98.0\n",
            "100.0\n",
            "805.0\n",
            "11.0\n",
            "302.0\n",
            "432.0\n",
            "368.0\n",
            "2592.0\n"
          ]
        }
      ],
      "source": [
        "for name, df in zip(filepaths, datasets): #classification minASPL\n",
        "  print(name, min_aspl(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKHe6GMIxsXi",
        "outputId": "8c1e8af5-8a04-41ec-c553-4277d8fd2153"
      },
      "outputs": [],
      "source": [
        "for name, df in zip(filepaths, all_dfs): #regression minASPL\n",
        "  print(name, min_aspl(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muRKaCh3F9vj"
      },
      "source": [
        "#### Drop useless features (manually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80lkCqEvW4xt"
      },
      "outputs": [],
      "source": [
        "df['target'] = df['\\'runtime\\'']\n",
        "df.drop(['\\'runtime\\'', 'id'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuF3SxYpP383"
      },
      "outputs": [],
      "source": [
        "def missing_input(df):\n",
        "    \"\"\"\n",
        "    Removes features with more than 50% of NaN values and impute missing values in a dataframe for both numerical and categorical columns.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The input dataframe with potential missing values.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The dataframe with missing values imputed. Numerical columns are imputed with the mean value,\n",
        "                      and categorical columns are imputed with the most frequent value.\n",
        "    \"\"\"\n",
        "    numerical_cols, cat_cols = column_types(df)\n",
        "\n",
        "    # Drop features with more than 50% of missing values\n",
        "    cols_to_drop = df.columns[df.isnull().mean() > 0.5]\n",
        "    df = df.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    # Numerical imputation with mean\n",
        "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    df[numerical_cols] = pd.DataFrame(imp_mean.fit_transform(df[numerical_cols]), columns=numerical_cols)\n",
        "\n",
        "    # Categorical imputation with the most frequent value\n",
        "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "    df[cat_cols] = pd.DataFrame(imp_mean.fit_transform(df[cat_cols]), columns=cat_cols)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Missing inputation for Classification datasets\n",
        "for name, df in zip(filepaths, all_dfs):\n",
        "  df = missing_input(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Missing inputation for Regression datasets\n",
        "for name, df in zip(filepaths, all_dfs):\n",
        "  df = missing_input(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
