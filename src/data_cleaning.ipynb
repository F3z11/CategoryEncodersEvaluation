{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dku6zN9YHBJq"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8gPqrWsMCwx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.impute import SimpleImputer\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPb_V9UwD7s"
      },
      "source": [
        "Compute minASPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuKWTBhowI57"
      },
      "outputs": [],
      "source": [
        "def column_types(df):\n",
        "    cols = df.columns\n",
        "    num_cols = df._get_numeric_data().columns.tolist()\n",
        "    cat_cols = list(set(cols) - set(num_cols))\n",
        "    return num_cols, cat_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-NPSJFkwDsW"
      },
      "outputs": [],
      "source": [
        "def min_aspl(data):\n",
        "  cat_cols = column_types(data)[1]\n",
        "  max_card = max(data[cat_cols].apply(lambda x: x.nunique()))\n",
        "  dim = len(data)\n",
        "  aspl = round(dim/max_card, 0)\n",
        "  return min_aspl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8pnbMJ6GC7B"
      },
      "source": [
        "Datasets importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtiPgNGvxpZN"
      },
      "outputs": [],
      "source": [
        "#Classification datasets\n",
        "datasets = []\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/census.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/mushrooms.csv', na_values='?'))\n",
        "\n",
        "churn = pd.read_csv('/data_clean/class/churn.csv', na_values='?')\n",
        "\n",
        "cols = ['\\'number_customer_service_calls\\'', '\\'state\\'', '\\'international_plan\\'', '\\'voice_mail_plan\\'', '\\'number_customer_service_calls\\'']\n",
        "for col in cols:\n",
        "    churn[col] = churn[col].astype('str')\n",
        "\n",
        "datasets.append(churn)\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/germancredit.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/breastcancer.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/autism_adult.csv', na_values='?'))\n",
        "\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/obesity.csv', na_values='?'))\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/car.csv', na_values='?'))\n",
        "\n",
        "cmc = pd.read_csv('/data_clean/class/cmc.csv', na_values='?')\n",
        "cols = ['wife_edu', 'husband_edu', 'wife_religion',\n",
        "       'wife_working', 'husband_occupation', 'standard_of_living_index',\n",
        "       'media_exposure', 'target']\n",
        "for col in cols:\n",
        "    cmc[col] = cmc[col].astype('str')\n",
        "\n",
        "datasets.append(cmc)\n",
        "\n",
        "datasets.append(pd.read_csv('/data_clean/class/nursery.csv', na_values='?'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZhTk0Oh3Ff0"
      },
      "outputs": [],
      "source": [
        "#Regression datasets\n",
        "filepaths = glob.glob('/data_clean/regr/*.csv')\n",
        "\n",
        "all_dfs = [pd.read_csv(fp, na_values='?') for fp in filepaths]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLg7FhQ7GMfy"
      },
      "source": [
        "Compute the minASPL value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgCQ_eXe3gCe",
        "outputId": "e3d0004b-03c5-4ab4-8e5d-83748104f2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1191.0\n",
            "677.0\n",
            "98.0\n",
            "100.0\n",
            "805.0\n",
            "11.0\n",
            "302.0\n",
            "432.0\n",
            "368.0\n",
            "2592.0\n"
          ]
        }
      ],
      "source": [
        "for name, df in zip(filepaths, datasets): #classification minASPL\n",
        "  print(name, min_aspl(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKHe6GMIxsXi",
        "outputId": "8c1e8af5-8a04-41ec-c553-4277d8fd2153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Codice/data/regr/ukair.csv 7440.0\n",
            "/content/drive/MyDrive/Codice/data/regr/forestfires.csv 43.0\n",
            "/content/drive/MyDrive/Codice/data/regr/baseball.csv 32.0\n",
            "/content/drive/MyDrive/Codice/data/regr/socmob.csv 68.0\n",
            "/content/drive/MyDrive/Codice/data/regr/avocado.csv 338.0\n",
            "/content/drive/MyDrive/Codice/data/regr/cpmp2015.csv 4.0\n"
          ]
        }
      ],
      "source": [
        "for name, df in zip(filepaths, all_dfs): #regression minASPL\n",
        "  print(name, min_aspl(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muRKaCh3F9vj"
      },
      "source": [
        "Drop useless features (manually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80lkCqEvW4xt"
      },
      "outputs": [],
      "source": [
        "df['target'] = df['\\'runtime\\'']\n",
        "df.drop(['\\'runtime\\'', 'id'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuF3SxYpP383"
      },
      "outputs": [],
      "source": [
        "def missing_input(df):\n",
        "    \"\"\"\n",
        "    Impute missing values in a dataframe for both numerical and categorical columns.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The input dataframe with potential missing values.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The dataframe with missing values imputed. Numerical columns are imputed with the mean value,\n",
        "                      and categorical columns are imputed with the most frequent value.\n",
        "    \"\"\"\n",
        "    numerical_cols, cat_cols = column_types(df)\n",
        "\n",
        "    # Numerical imputation with mean\n",
        "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    df[numerical_cols] = pd.DataFrame(imp_mean.fit_transform(df[numerical_cols]), columns=numerical_cols)\n",
        "\n",
        "    # Categorical imputation with the most frequent value\n",
        "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "    df[cat_cols] = pd.DataFrame(imp_mean.fit_transform(df[cat_cols]), columns=cat_cols)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE8O1Uo6Y3Bq"
      },
      "outputs": [],
      "source": [
        "df['\\'VehBCost\\''] = pd.to_numeric(df['\\'VehBCost\\''], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_q5DhvuUinU"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df = pd.DataFrame(imp_mean.fit_transform(df), columns=df.columns)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
